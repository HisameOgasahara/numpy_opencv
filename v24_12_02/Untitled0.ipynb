{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSH2ncfc_zJu",
    "outputId": "864bb81e-d21a-427d-8362-1d0c85ec2c83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
      "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
      "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.39)\n",
      "Requirement already satisfied: gitpython in /usr/local/lib/python3.10/dist-packages (3.1.43)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.36.0)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.6)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.32.3)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.12)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython) (4.0.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg>=0.2.0->moviepy) (75.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
      "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.39)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Setting up the system...\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Created directory: /content/drive/MyDrive/lane_detection/input\n",
      "Created directory: /content/drive/MyDrive/lane_detection/output\n",
      "Created directory: /content/drive/MyDrive/lane_detection/models\n",
      "Created directory: /content/drive/MyDrive/lane_detection/calibration\n",
      "YOLO model loaded successfully!\n",
      "Starting camera calibration...\n",
      "Camera calibration completed successfully!\n",
      "\n",
      "Checking for video files in the input directory...\n",
      "Input directory: /content/drive/MyDrive/lane_detection/input\n",
      "\n",
      "Found 1 video file(s) to process.\n",
      "\n",
      "Processing video 1/1: 3.mp4\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 14.0ms\n",
      "Speed: 1.9ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Moviepy - Building video /content/drive/MyDrive/lane_detection/output/output_3.mp4.\n",
      "Moviepy - Writing video /content/drive/MyDrive/lane_detection/output/output_3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   0%|          | 0/1800 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 truck, 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   0%|          | 2/1800 [00:00<02:27, 12.22it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 truck, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 15.4ms\n",
      "Speed: 2.6ms preprocess, 15.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   0%|          | 4/1800 [00:00<04:14,  7.04it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 bus, 1 truck, 14.5ms\n",
      "Speed: 2.1ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   0%|          | 5/1800 [00:00<04:36,  6.50it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 1 truck, 10.2ms\n",
      "Speed: 2.2ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   0%|          | 6/1800 [00:00<04:42,  6.35it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 1 truck, 10.5ms\n",
      "Speed: 2.2ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   0%|          | 7/1800 [00:01<04:48,  6.21it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   0%|          | 8/1800 [00:01<04:54,  6.08it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 1 truck, 10.8ms\n",
      "Speed: 2.2ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   0%|          | 9/1800 [00:01<04:58,  6.01it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 1 truck, 15.0ms\n",
      "Speed: 2.6ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   1%|          | 10/1800 [00:01<05:05,  5.85it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 2 trucks, 10.9ms\n",
      "Speed: 2.2ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   1%|          | 11/1800 [00:01<05:09,  5.78it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 1 truck, 10.4ms\n",
      "Speed: 2.9ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   1%|          | 12/1800 [00:01<05:08,  5.79it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 1 truck, 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   1%|          | 13/1800 [00:02<05:09,  5.77it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 2 trucks, 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   1%|          | 14/1800 [00:02<05:06,  5.83it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 1 truck, 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   1%|          | 15/1800 [00:02<05:17,  5.62it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 1 truck, 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   1%|          | 16/1800 [00:02<05:10,  5.74it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 2 trucks, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   1%|          | 17/1800 [00:02<05:11,  5.72it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 truck, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   1%|          | 18/1800 [00:02<05:10,  5.74it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 2 trucks, 10.7ms\n",
      "Speed: 3.0ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   1%|          | 19/1800 [00:03<05:07,  5.79it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 2 trucks, 10.2ms\n",
      "Speed: 3.4ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   1%|          | 20/1800 [00:03<05:03,  5.87it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 2 trucks, 10.5ms\n",
      "Speed: 2.3ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   1%|          | 21/1800 [00:03<05:10,  5.72it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 2 trucks, 10.5ms\n",
      "Speed: 3.1ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   1%|          | 22/1800 [00:03<05:05,  5.83it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 truck, 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   1%|▏         | 23/1800 [00:03<05:11,  5.70it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 truck, 10.7ms\n",
      "Speed: 3.4ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   1%|▏         | 24/1800 [00:04<05:05,  5.81it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 truck, 12.0ms\n",
      "Speed: 2.3ms preprocess, 12.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   1%|▏         | 25/1800 [00:04<05:06,  5.80it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 bus, 1 truck, 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   1%|▏         | 26/1800 [00:04<05:02,  5.86it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 2 trucks, 15.3ms\n",
      "Speed: 3.1ms preprocess, 15.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 27/1800 [00:04<05:11,  5.68it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 2 trucks, 10.7ms\n",
      "Speed: 2.1ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 28/1800 [00:04<05:05,  5.80it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 2 trucks, 11.4ms\n",
      "Speed: 2.1ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 29/1800 [00:04<05:13,  5.66it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 2 trucks, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 30/1800 [00:05<05:08,  5.73it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 2 trucks, 11.1ms\n",
      "Speed: 3.4ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 31/1800 [00:05<05:10,  5.70it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 3 trucks, 12.0ms\n",
      "Speed: 2.4ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 32/1800 [00:05<05:08,  5.74it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 bus, 3 trucks, 14.0ms\n",
      "Speed: 2.1ms preprocess, 14.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 33/1800 [00:05<05:11,  5.67it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 2 trucks, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 34/1800 [00:05<05:05,  5.77it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 2 trucks, 18.3ms\n",
      "Speed: 2.3ms preprocess, 18.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 35/1800 [00:05<05:11,  5.66it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 1 bus, 2 trucks, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 36/1800 [00:06<05:04,  5.80it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 2 trucks, 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 37/1800 [00:06<05:01,  5.84it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 2 trucks, 12.1ms\n",
      "Speed: 2.4ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 38/1800 [00:06<05:08,  5.71it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 2 trucks, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 39/1800 [00:06<05:08,  5.72it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 2 trucks, 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 40/1800 [00:06<05:04,  5.79it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 2 trucks, 18.2ms\n",
      "Speed: 2.4ms preprocess, 18.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 41/1800 [00:06<05:18,  5.52it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 3 trucks, 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 42/1800 [00:07<05:15,  5.57it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 cars, 2 trucks, 11.8ms\n",
      "Speed: 2.1ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 43/1800 [00:07<05:12,  5.62it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 3 trucks, 33.1ms\n",
      "Speed: 4.0ms preprocess, 33.1ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▏         | 44/1800 [00:07<06:35,  4.44it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 3 trucks, 15.1ms\n",
      "Speed: 2.3ms preprocess, 15.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   2%|▎         | 45/1800 [00:07<07:15,  4.03it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 cars, 2 trucks, 15.1ms\n",
      "Speed: 3.4ms preprocess, 15.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   3%|▎         | 46/1800 [00:08<06:46,  4.31it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 2 trucks, 11.0ms\n",
      "Speed: 2.4ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   3%|▎         | 47/1800 [00:08<06:15,  4.67it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 14.1ms\n",
      "Speed: 4.0ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   3%|▎         | 48/1800 [00:08<06:22,  4.58it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 17.6ms\n",
      "Speed: 2.1ms preprocess, 17.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   3%|▎         | 49/1800 [00:08<06:30,  4.48it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 bus, 1 truck, 21.0ms\n",
      "Speed: 6.1ms preprocess, 21.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   3%|▎         | 50/1800 [00:09<06:31,  4.47it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 bus, 3 trucks, 20.3ms\n",
      "Speed: 5.4ms preprocess, 20.3ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   3%|▎         | 51/1800 [00:09<06:54,  4.22it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 3 trucks, 29.0ms\n",
      "Speed: 4.2ms preprocess, 29.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   3%|▎         | 52/1800 [00:09<07:34,  3.84it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 2 trucks, 15.9ms\n",
      "Speed: 2.3ms preprocess, 15.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   3%|▎         | 53/1800 [00:09<08:13,  3.54it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 3 trucks, 17.5ms\n",
      "Speed: 5.8ms preprocess, 17.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   3%|▎         | 54/1800 [00:10<08:25,  3.45it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 3 trucks, 17.4ms\n",
      "Speed: 2.2ms preprocess, 17.4ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   3%|▎         | 55/1800 [00:10<09:37,  3.02it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 2 trucks, 35.6ms\n",
      "Speed: 2.1ms preprocess, 35.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   3%|▎         | 56/1800 [00:11<09:44,  2.98it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 15.4ms\n",
      "Speed: 3.0ms preprocess, 15.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   3%|▎         | 57/1800 [00:11<10:09,  2.86it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 18.8ms\n",
      "Speed: 2.9ms preprocess, 18.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   3%|▎         | 58/1800 [00:11<09:42,  2.99it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 21.5ms\n",
      "Speed: 2.2ms preprocess, 21.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   3%|▎         | 59/1800 [00:12<09:35,  3.03it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 23.9ms\n",
      "Speed: 2.8ms preprocess, 23.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   3%|▎         | 60/1800 [00:12<10:25,  2.78it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 15.6ms\n",
      "Speed: 3.2ms preprocess, 15.6ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   3%|▎         | 61/1800 [00:12<10:34,  2.74it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 13.8ms\n",
      "Speed: 4.6ms preprocess, 13.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   3%|▎         | 62/1800 [00:13<10:02,  2.89it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 2 trucks, 22.0ms\n",
      "Speed: 2.8ms preprocess, 22.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▎         | 63/1800 [00:13<10:20,  2.80it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 2 trucks, 30.3ms\n",
      "Speed: 6.0ms preprocess, 30.3ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▎         | 64/1800 [00:13<10:15,  2.82it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 2 trucks, 21.7ms\n",
      "Speed: 5.0ms preprocess, 21.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▎         | 65/1800 [00:14<10:13,  2.83it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 2 trucks, 19.1ms\n",
      "Speed: 5.0ms preprocess, 19.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▎         | 66/1800 [00:14<10:12,  2.83it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 27.3ms\n",
      "Speed: 2.0ms preprocess, 27.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▎         | 67/1800 [00:14<10:20,  2.80it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 cars, 1 bus, 1 truck, 24.8ms\n",
      "Speed: 2.7ms preprocess, 24.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▍         | 68/1800 [00:15<10:14,  2.82it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 bus, 1 truck, 31.0ms\n",
      "Speed: 5.3ms preprocess, 31.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▍         | 69/1800 [00:15<09:25,  3.06it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 3 cars, 1 bus, 1 truck, 17.0ms\n",
      "Speed: 2.2ms preprocess, 17.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▍         | 70/1800 [00:15<08:31,  3.38it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 truck, 18.0ms\n",
      "Speed: 2.3ms preprocess, 18.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▍         | 71/1800 [00:15<07:48,  3.69it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 truck, 19.8ms\n",
      "Speed: 2.3ms preprocess, 19.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▍         | 72/1800 [00:16<07:17,  3.95it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 5 cars, 1 truck, 17.7ms\n",
      "Speed: 3.1ms preprocess, 17.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▍         | 73/1800 [00:16<07:28,  3.85it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 truck, 16.9ms\n",
      "Speed: 2.3ms preprocess, 16.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▍         | 74/1800 [00:16<07:06,  4.04it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 truck, 16.5ms\n",
      "Speed: 2.1ms preprocess, 16.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▍         | 75/1800 [00:16<07:12,  3.99it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 4 cars, 1 truck, 18.6ms\n",
      "Speed: 2.1ms preprocess, 18.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▍         | 76/1800 [00:17<07:38,  3.76it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 4 cars, 1 truck, 26.2ms\n",
      "Speed: 2.2ms preprocess, 26.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▍         | 77/1800 [00:17<08:23,  3.42it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 17.7ms\n",
      "Speed: 2.3ms preprocess, 17.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▍         | 78/1800 [00:17<08:16,  3.47it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 19.5ms\n",
      "Speed: 2.3ms preprocess, 19.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▍         | 79/1800 [00:18<09:44,  2.94it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 3 cars, 1 truck, 23.1ms\n",
      "Speed: 2.1ms preprocess, 23.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▍         | 80/1800 [00:18<09:34,  2.99it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 20.2ms\n",
      "Speed: 2.3ms preprocess, 20.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   4%|▍         | 81/1800 [00:18<09:31,  3.01it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 truck, 18.8ms\n",
      "Speed: 2.5ms preprocess, 18.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   5%|▍         | 82/1800 [00:19<08:36,  3.33it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 truck, 17.8ms\n",
      "Speed: 2.6ms preprocess, 17.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   5%|▍         | 83/1800 [00:19<07:52,  3.63it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 truck, 17.3ms\n",
      "Speed: 2.6ms preprocess, 17.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   5%|▍         | 84/1800 [00:19<07:23,  3.87it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 2 trucks, 17.7ms\n",
      "Speed: 5.1ms preprocess, 17.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   5%|▍         | 85/1800 [00:19<07:21,  3.88it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 17.7ms\n",
      "Speed: 2.8ms preprocess, 17.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   5%|▍         | 86/1800 [00:20<07:07,  4.01it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 cars, 20.8ms\n",
      "Speed: 2.6ms preprocess, 20.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   5%|▍         | 87/1800 [00:20<06:51,  4.16it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 17.7ms\n",
      "Speed: 5.3ms preprocess, 17.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   5%|▍         | 88/1800 [00:20<06:46,  4.21it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 16.9ms\n",
      "Speed: 4.5ms preprocess, 16.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   5%|▍         | 89/1800 [00:20<07:01,  4.06it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 17.2ms\n",
      "Speed: 2.2ms preprocess, 17.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   5%|▌         | 90/1800 [00:21<06:47,  4.19it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 16.7ms\n",
      "Speed: 3.1ms preprocess, 16.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   5%|▌         | 91/1800 [00:21<06:33,  4.35it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 7 cars, 1 truck, 25.6ms\n",
      "Speed: 6.6ms preprocess, 25.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   5%|▌         | 92/1800 [00:21<06:34,  4.33it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 cars, 1 truck, 19.5ms\n",
      "Speed: 5.4ms preprocess, 19.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   5%|▌         | 93/1800 [00:21<06:58,  4.08it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 cars, 1 truck, 17.7ms\n",
      "Speed: 2.7ms preprocess, 17.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   5%|▌         | 94/1800 [00:22<06:45,  4.20it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 cars, 18.5ms\n",
      "Speed: 2.5ms preprocess, 18.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   5%|▌         | 95/1800 [00:22<06:34,  4.33it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 11.9ms\n",
      "Speed: 3.0ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   5%|▌         | 96/1800 [00:22<06:30,  4.36it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 16.5ms\n",
      "Speed: 2.7ms preprocess, 16.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   5%|▌         | 97/1800 [00:22<06:46,  4.19it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 17.5ms\n",
      "Speed: 2.5ms preprocess, 17.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   5%|▌         | 98/1800 [00:22<06:34,  4.32it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 cars, 1 truck, 20.6ms\n",
      "Speed: 3.4ms preprocess, 20.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   6%|▌         | 99/1800 [00:23<06:31,  4.34it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 2 trucks, 17.6ms\n",
      "Speed: 2.6ms preprocess, 17.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   6%|▌         | 100/1800 [00:23<06:23,  4.44it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 20.1ms\n",
      "Speed: 2.5ms preprocess, 20.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   6%|▌         | 101/1800 [00:23<06:51,  4.13it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 19.5ms\n",
      "Speed: 2.6ms preprocess, 19.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   6%|▌         | 102/1800 [00:23<06:45,  4.19it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 10.1ms\n",
      "Speed: 5.3ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   6%|▌         | 103/1800 [00:24<06:38,  4.26it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 12.2ms\n",
      "Speed: 2.1ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   6%|▌         | 104/1800 [00:24<06:28,  4.37it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 19.8ms\n",
      "Speed: 4.9ms preprocess, 19.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   6%|▌         | 105/1800 [00:24<06:53,  4.10it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 truck, 23.2ms\n",
      "Speed: 2.2ms preprocess, 23.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   6%|▌         | 106/1800 [00:24<06:51,  4.11it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 1 truck, 11.7ms\n",
      "Speed: 6.3ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   6%|▌         | 107/1800 [00:25<06:40,  4.23it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 19.2ms\n",
      "Speed: 6.1ms preprocess, 19.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   6%|▌         | 108/1800 [00:25<06:47,  4.15it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 cars, 1 truck, 19.9ms\n",
      "Speed: 5.6ms preprocess, 19.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   6%|▌         | 109/1800 [00:25<07:40,  3.67it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 cars, 1 truck, 16.7ms\n",
      "Speed: 2.2ms preprocess, 16.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   6%|▌         | 110/1800 [00:25<07:57,  3.54it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 2 trucks, 15.4ms\n",
      "Speed: 6.2ms preprocess, 15.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   6%|▌         | 111/1800 [00:26<08:08,  3.46it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 2 trucks, 25.6ms\n",
      "Speed: 2.1ms preprocess, 25.6ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   6%|▌         | 112/1800 [00:26<08:49,  3.19it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 2 trucks, 29.7ms\n",
      "Speed: 5.8ms preprocess, 29.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   6%|▋         | 113/1800 [00:27<09:30,  2.96it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 2 trucks, 18.0ms\n",
      "Speed: 2.2ms preprocess, 18.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   6%|▋         | 114/1800 [00:27<09:33,  2.94it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 1 truck, 20.9ms\n",
      "Speed: 2.4ms preprocess, 20.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rt:   6%|▋         | 115/1800 [00:27<09:33,  2.94it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 cars, 2 trucks, 28.2ms\n",
      "Speed: 2.1ms preprocess, 28.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Lane_Detection_Colab_Final.ipynb\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/your_notebook_id\n",
    "\n",
    "# Advanced Lane Detection with Direction\n",
    "\"\"\"\n",
    "\n",
    "# Install required packages\n",
    "!pip install opencv-python moviepy ultralytics gitpython\n",
    "!pip install huggingface_hub\n",
    "!pip install --upgrade ultralytics\n",
    "\n",
    "# Import required libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import VideoFileClip\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from google.colab import files, drive\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import git\n",
    "from huggingface_hub import hf_hub_download\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "\"\"\"## 1. 코랩 및 yolo/캘리브레이션 데이터\"\"\"\n",
    "\n",
    "# Global variables\n",
    "CAMERA_MTX = None\n",
    "CAMERA_DIST = None\n",
    "model = None  # Global YOLO model variable\n",
    "PREV_METRICS = None\n",
    "SMOOTHING_FACTOR = 0.3  # Adjust this value to control smoothing (0-1)\n",
    "FRAME_TIME = time.time()\n",
    "SPEED_MPH = 0\n",
    "\n",
    "def setup_directories():\n",
    "    \"\"\"Setup necessary directories in Google Drive.\"\"\"\n",
    "    # Mount Google Drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Define base directory in Google Drive\n",
    "    base_dir = '/content/drive/MyDrive/lane_detection'\n",
    "\n",
    "    # Create necessary directories\n",
    "    directories = ['input', 'output', 'models', 'calibration']\n",
    "    for dir_name in directories:\n",
    "        dir_path = os.path.join(base_dir, dir_name)\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        print(f\"Created directory: {dir_path}\")\n",
    "\n",
    "    return base_dir\n",
    "\n",
    "def download_yolo_model(base_dir):\n",
    "    \"\"\"Download YOLO model from Hugging Face.\"\"\"\n",
    "    global model\n",
    "    model_path = os.path.join(base_dir, 'models', 'yolo11n-seg.pt')\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(\"Downloading YOLO model...\")\n",
    "        try:\n",
    "            # Direct download command for YOLO model\n",
    "            !wget -P {os.path.dirname(model_path)} https://huggingface.co/Ultralytics/YOLO11/resolve/main/yolo11n-seg.pt\n",
    "            print(\"YOLO model downloaded successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading YOLO model: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    # Initialize YOLO model\n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "        print(\"YOLO model loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading YOLO model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    return model_path\n",
    "\n",
    "def clone_calibration_data(base_dir):\n",
    "    \"\"\"Clone calibration data from Hugging Face repository.\"\"\"\n",
    "    calibration_dir = os.path.join(base_dir, 'calibration')\n",
    "\n",
    "    if not os.path.exists(os.path.join(calibration_dir, 'camera_cal')):\n",
    "        print(\"Cloning calibration data...\")\n",
    "        repo_url = \"https://huggingface.co/sdgsdggds/camera\"\n",
    "        git.Repo.clone_from(repo_url, calibration_dir)\n",
    "        print(\"Calibration data cloned successfully!\")\n",
    "\n",
    "    return os.path.join(calibration_dir, 'camera_cal')\n",
    "\n",
    "def initialize_system():\n",
    "    \"\"\"Initialize the entire system.\"\"\"\n",
    "    print(\"Setting up the system...\")\n",
    "\n",
    "    # Setup directories\n",
    "    base_dir = setup_directories()\n",
    "\n",
    "    # Download YOLO model\n",
    "    model_path = download_yolo_model(base_dir)\n",
    "\n",
    "    # Clone calibration data\n",
    "    calibration_dir = clone_calibration_data(base_dir)\n",
    "\n",
    "    return base_dir, calibration_dir\n",
    "\n",
    "\n",
    "\"\"\"## 2. Camera Calibration\"\"\"\n",
    "\n",
    "def initialize_calibration(calibration_dir):\n",
    "    \"\"\"Initialize camera calibration using chessboard images.\"\"\"\n",
    "    global CAMERA_MTX, CAMERA_DIST\n",
    "    nx = 9  # number of inside corners in x\n",
    "    ny = 6  # number of inside corners in y\n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "\n",
    "    # Prepare object points\n",
    "    objp = np.zeros((ny*nx,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "    # Calibration images should be in a folder named 'camera_cal' in your Google Drive\n",
    "    cal_images = [f for f in os.listdir(calibration_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    if not cal_images:\n",
    "        print(\"No calibration images found in 'camera_cal' folder!\")\n",
    "        return False\n",
    "\n",
    "    for fname in cal_images:\n",
    "        img = cv2.imread(os.path.join(calibration_dir, fname))\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "        if ret:\n",
    "            imgpoints.append(corners)\n",
    "            objpoints.append(objp)\n",
    "\n",
    "    if len(objpoints) == 0:\n",
    "        print(\"No valid calibration images found!\")\n",
    "        return False\n",
    "\n",
    "    # Calibrate camera\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    CAMERA_MTX = mtx\n",
    "    CAMERA_DIST = dist\n",
    "    print(\"Camera calibration completed successfully!\")\n",
    "    return True\n",
    "\n",
    "\"\"\"## 3. Image Processing Functions\"\"\"\n",
    "\n",
    "def warp(img, mtx, dist):\n",
    "    \"\"\"Apply perspective transform to input image.\"\"\"\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    offset = 300\n",
    "\n",
    "    src = np.float32([\n",
    "        (190, 720),   # Bottom left\n",
    "        (596, 447),   # Top left\n",
    "        (685, 447),   # Top right\n",
    "        (1125, 720)   # Bottom right\n",
    "    ])\n",
    "\n",
    "    dst = np.float32([\n",
    "        [offset, img_size[1]],             # Bottom left\n",
    "        [offset, 0],                       # Top left\n",
    "        [img_size[0]-offset, 0],           # Top right\n",
    "        [img_size[0]-offset, img_size[1]]  # Bottom right\n",
    "    ])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(undist, M, img_size)\n",
    "\n",
    "    return warped, M_inv\n",
    "\n",
    "def binary_thresholded(img):\n",
    "    \"\"\"Create binary thresholded image using color and gradient thresholds.\"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    sx_binary = np.zeros_like(scaled_sobel)\n",
    "    sx_binary[(scaled_sobel >= 30) & (scaled_sobel <= 255)] = 1\n",
    "\n",
    "    # Threshold for white pixels\n",
    "    white_binary = np.zeros_like(gray)\n",
    "    white_binary[(gray > 200) & (gray <= 255)] = 1\n",
    "\n",
    "    # Threshold for yellow lines using HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    H = hls[:,:,0]\n",
    "    S = hls[:,:,2]\n",
    "\n",
    "    sat_binary = np.zeros_like(S)\n",
    "    sat_binary[(S > 90) & (S <= 255)] = 1\n",
    "\n",
    "    hue_binary = np.zeros_like(H)\n",
    "    hue_binary[(H > 10) & (H <= 25)] = 1\n",
    "\n",
    "    # Combine thresholds\n",
    "    binary_1 = cv2.bitwise_or(sx_binary, white_binary)\n",
    "    binary_2 = cv2.bitwise_or(sat_binary, hue_binary)\n",
    "    binary = cv2.bitwise_or(binary_1, binary_2)\n",
    "\n",
    "    return binary\n",
    "\n",
    "def combine_images(main_image, process_images, labels=None):\n",
    "    \"\"\"Combine main image with processing steps displayed vertically.\"\"\"\n",
    "    # Get dimensions\n",
    "    h, w = main_image.shape[:2]\n",
    "\n",
    "    # Calculate dimensions for processing images\n",
    "    proc_height = h // len(process_images)  # Height for each processing image\n",
    "    proc_width = w // 2  # Width for processing images (half of main image)\n",
    "\n",
    "    # Resize main image to take up left half\n",
    "    main_resized = cv2.resize(main_image, (proc_width*2, h))\n",
    "\n",
    "    # Process and resize the processing images\n",
    "    processed = []\n",
    "    for img in process_images:\n",
    "        # Convert if grayscale\n",
    "        if len(img.shape) == 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        # Resize to fit the right half\n",
    "        img_resized = cv2.resize(img, (proc_width, proc_height))\n",
    "        processed.append(img_resized)\n",
    "\n",
    "    # Stack processing images vertically\n",
    "    right_side = np.vstack(processed)\n",
    "\n",
    "    # Combine main image with processing images\n",
    "    combined = np.hstack((main_resized, right_side))\n",
    "\n",
    "    # Add labels if provided\n",
    "    if labels:\n",
    "        for i, label in enumerate(labels):\n",
    "            x = proc_width * 2 + 10  # Position labels on right side\n",
    "            y = (i * proc_height) + 30  # Vertical position for each label\n",
    "            cv2.putText(combined, label, (x, y),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    return combined\n",
    "\n",
    "\"\"\"## 4. Lane Detection Functions\"\"\"\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    \"\"\"Find lane pixels in the binary warped image.\"\"\"\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "    midpoint = int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    nwindows = 9\n",
    "    margin = 100\n",
    "    minpix = 50\n",
    "\n",
    "    window_height = int(binary_warped.shape[0]//nwindows)\n",
    "\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped)) * 255\n",
    "\n",
    "    for window in range(nwindows):\n",
    "        win_y_low = binary_warped.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = binary_warped.shape[0] - window * window_height\n",
    "\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "                         (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "                          (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "        cv2.rectangle(out_img, (win_xleft_low, win_y_low), (win_xleft_high, win_y_high), (0, 255, 0), 2)\n",
    "        cv2.rectangle(out_img, (win_xright_low, win_y_low), (win_xright_high, win_y_high), (0, 255, 0), 2)\n",
    "\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return out_img, leftx, lefty, rightx, righty\n",
    "\n",
    "def determine_curve_direction(left_fit, right_fit):\n",
    "    \"\"\"Determine the direction of the curve based on polynomial coefficients.\"\"\"\n",
    "    if left_fit is None or right_fit is None:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    avg_curve = (left_fit[0] + right_fit[0]) / 2\n",
    "\n",
    "    if abs(avg_curve) < 5e-4:  # 임계값을 1e-3에서 5e-4로 감소\n",
    "        return \"↑↑\"\n",
    "    elif avg_curve > 0:\n",
    "        return \"→→\"\n",
    "    else:\n",
    "        return \"←←\"\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    \"\"\"Fit polynomial to binary image with lane lines.\"\"\"\n",
    "    _, leftx, lefty, rightx, righty = find_lane_pixels(binary_warped)\n",
    "\n",
    "    if len(leftx) == 0 or len(rightx) == 0:\n",
    "        return None, None\n",
    "\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    return left_fit, right_fit\n",
    "\n",
    "def calculate_tilt(left_fit, right_fit, img_shape):\n",
    "    \"\"\"Calculate the tilt value and direction based on lane line polynomials.\"\"\"\n",
    "    # Calculate position of lines at the bottom of the image\n",
    "    y_eval = img_shape[0]\n",
    "    left_x = left_fit[0]*y_eval**2 + left_fit[1]*y_eval + left_fit[2]\n",
    "    right_x = right_fit[0]*y_eval**2 + right_fit[1]*y_eval + right_fit[2]\n",
    "\n",
    "    # Calculate center position\n",
    "    center_pos = (left_x + right_x) / 2\n",
    "    image_center = img_shape[1] / 2\n",
    "\n",
    "    # Calculate offset from center (positive is right tilt, negative is left tilt)\n",
    "    offset = center_pos - image_center\n",
    "\n",
    "    # Convert offset to a tilt value (scale factor can be adjusted)\n",
    "    tilt_value = round(offset / (image_center) * 100, 1)  # Convert to percentage\n",
    "\n",
    "    if abs(tilt_value) < 1.0:  # Threshold for considering it centered\n",
    "        return 0, \"center\"\n",
    "    elif tilt_value > 0:\n",
    "        return tilt_value, \"right\"\n",
    "    else:\n",
    "        return abs(tilt_value), \"left\"\n",
    "\n",
    "def smooth_metrics(new_metrics, prev_metrics):\n",
    "    \"\"\"Apply exponential smoothing to metrics.\"\"\"\n",
    "    if prev_metrics is None:\n",
    "        return new_metrics\n",
    "\n",
    "    smoothed = {}\n",
    "    for key in new_metrics:\n",
    "        if key in prev_metrics:\n",
    "            smoothed[key] = (SMOOTHING_FACTOR * new_metrics[key] +\n",
    "                           (1 - SMOOTHING_FACTOR) * prev_metrics[key])\n",
    "        else:\n",
    "            smoothed[key] = new_metrics[key]\n",
    "    return smoothed\n",
    "\n",
    "def estimate_speed(curve_radius, frame_time):\n",
    "    \"\"\"Estimate speed based on curve radius and frame time.\"\"\"\n",
    "    global SPEED_MPH\n",
    "\n",
    "    # Get time difference\n",
    "    current_time = time.time()\n",
    "    dt = current_time - frame_time\n",
    "\n",
    "    # Estimate speed based on curve radius (larger radius = higher possible speed)\n",
    "    # This is a simplified model and would need calibration for accurate results\n",
    "    max_speed = min(75, curve_radius / 30)  # mph, capped at 75 mph\n",
    "    target_speed = max_speed * 0.8  # Assume driving at 80% of max safe speed\n",
    "\n",
    "    # Smooth speed changes\n",
    "    SPEED_MPH = SPEED_MPH * 0.9 + target_speed * 0.1\n",
    "\n",
    "    return SPEED_MPH, current_time\n",
    "\n",
    "def check_lane_departure(position_offset, lane_width):\n",
    "    \"\"\"Check if vehicle is departing from lane.\"\"\"\n",
    "    # Warning thresholds (as percentage of lane width)\n",
    "    warning_threshold = lane_width * 0.3\n",
    "    critical_threshold = lane_width * 0.4\n",
    "\n",
    "    if abs(position_offset) > critical_threshold:\n",
    "        return \"CRITICAL\", (0, 0, 255)  # Red for critical\n",
    "    elif abs(position_offset) > warning_threshold:\n",
    "        return \"WARNING\", (0, 255, 255)  # Yellow for warning\n",
    "    return \"NORMAL\", (0, 255, 0)  # Green for normal\n",
    "\n",
    "def calculate_metrics(left_fit, right_fit, binary_warped, leftx, lefty, rightx, righty):\n",
    "    \"\"\"Calculate various lane metrics.\"\"\"\n",
    "    global PREV_METRICS, FRAME_TIME\n",
    "\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720  # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700  # meters per pixel in x dimension\n",
    "\n",
    "    # Calculate curve radius\n",
    "    y_eval = binary_warped.shape[0]\n",
    "\n",
    "    # Fit polynomials in world space\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "\n",
    "    # Calculate curve radius\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) \\\n",
    "                    / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) \\\n",
    "                    / np.absolute(2*right_fit_cr[0])\n",
    "    curve_radius = round((left_curverad + right_curverad) / 2, 1)\n",
    "\n",
    "    # Calculate lane width\n",
    "    left_x = left_fit[0]*y_eval**2 + left_fit[1]*y_eval + left_fit[2]\n",
    "    right_x = right_fit[0]*y_eval**2 + right_fit[1]*y_eval + right_fit[2]\n",
    "    lane_width = (right_x - left_x) * xm_per_pix\n",
    "    lane_width = round(lane_width, 2)\n",
    "\n",
    "    # Calculate vehicle position offset\n",
    "    center_pos = (left_x + right_x) / 2\n",
    "    image_center = binary_warped.shape[1] / 2\n",
    "    offset = (center_pos - image_center) * xm_per_pix\n",
    "    position_offset = round(offset, 2)\n",
    "\n",
    "    # Calculate lane detection confidence score (0-100)\n",
    "    # Based on number of detected pixels and lane width consistency\n",
    "    expected_width = 3.7  # meters\n",
    "    width_score = max(0, 100 - abs(lane_width - expected_width) * 50)\n",
    "    pixel_score = min(100, (len(leftx) + len(rightx)) / 50)\n",
    "    confidence_score = round((width_score + pixel_score) / 2, 1)\n",
    "\n",
    "    # Calculate speed\n",
    "    speed, new_frame_time = estimate_speed(curve_radius, FRAME_TIME)\n",
    "    FRAME_TIME = new_frame_time\n",
    "\n",
    "    metrics = {\n",
    "        'curve_radius': curve_radius,\n",
    "        'lane_width': lane_width,\n",
    "        'position_offset': position_offset,\n",
    "        'confidence': confidence_score,\n",
    "        'speed': speed\n",
    "    }\n",
    "\n",
    "    # Apply smoothing\n",
    "    smoothed_metrics = smooth_metrics(metrics, PREV_METRICS)\n",
    "    PREV_METRICS = smoothed_metrics\n",
    "\n",
    "    return smoothed_metrics\n",
    "\n",
    "def draw_metrics(image, metrics):\n",
    "    \"\"\"Draw lane metrics on the image.\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # Check lane departure status\n",
    "    departure_status, status_color = check_lane_departure(\n",
    "        metrics['position_offset'], metrics['lane_width'])\n",
    "\n",
    "    # Define metrics positions (left side of image)\n",
    "    start_x = 10\n",
    "    start_y = 30\n",
    "    line_height = 30\n",
    "\n",
    "    # Metrics text with units\n",
    "    metrics_text = [\n",
    "        f\"Curve Radius: {metrics['curve_radius']:.1f}m\",\n",
    "        f\"Lane Width: {metrics['lane_width']:.2f}m\",\n",
    "        f\"Position Offset: {metrics['position_offset']:+.2f}m\",\n",
    "        f\"Speed: {metrics['speed']:.1f}mph\",\n",
    "        f\"Confidence: {metrics['confidence']:.1f}%\"\n",
    "    ]\n",
    "\n",
    "    # Draw background rectangle for better visibility\n",
    "    padding = 10\n",
    "    rect_height = len(metrics_text) * line_height + 2 * padding\n",
    "    rect_width = 300\n",
    "    cv2.rectangle(image, (start_x - padding, start_y - padding - 20),\n",
    "                 (start_x + rect_width, start_y + rect_height),\n",
    "                 (0, 0, 0), -1)\n",
    "    cv2.rectangle(image, (start_x - padding, start_y - padding - 20),\n",
    "                 (start_x + rect_width, start_y + rect_height),\n",
    "                 (255, 255, 255), 1)\n",
    "\n",
    "    # Draw metrics text\n",
    "    for i, text in enumerate(metrics_text):\n",
    "        y_pos = start_y + i * line_height\n",
    "        cv2.putText(image, text, (start_x, y_pos),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    # Draw lane departure warning if not normal\n",
    "    if departure_status != \"NORMAL\":\n",
    "        warning_text = f\"Lane Departure {departure_status}!\"\n",
    "        text_size = cv2.getTextSize(warning_text, cv2.FONT_HERSHEY_SIMPLEX, 1.0, 2)[0]\n",
    "        warn_x = (w - text_size[0]) // 2\n",
    "        cv2.putText(image, warning_text, (warn_x, h - 50),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, status_color, 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "def draw_tilt_indicator(image, tilt_value, direction):\n",
    "    \"\"\"Draw tilt indicator with purple line and value.\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    center_x = w // 2\n",
    "    center_y = h // 2\n",
    "    line_length = 50  # Length of the indicator line\n",
    "\n",
    "    # Draw center vertical line\n",
    "    cv2.line(image, (center_x, center_y - 60), (center_x, center_y + 60), (128, 128, 128), 1)\n",
    "\n",
    "    if direction == \"center\":\n",
    "        # Draw horizontal line in the center\n",
    "        cv2.line(image, (center_x - line_length//2, center_y),\n",
    "                (center_x + line_length//2, center_y), (255, 0, 255), 2)\n",
    "        text = \"0\"\n",
    "    else:\n",
    "        if direction == \"right\":\n",
    "            # Draw tilted line to the right\n",
    "            end_x = center_x + line_length//2\n",
    "            end_y = center_y - 20\n",
    "            text = f\"right: {tilt_value}\"\n",
    "        else:  # left\n",
    "            # Draw tilted line to the left\n",
    "            end_x = center_x - line_length//2\n",
    "            end_y = center_y - 20\n",
    "            text = f\"left: {tilt_value}\"\n",
    "\n",
    "        cv2.line(image, (center_x, center_y), (end_x, end_y), (255, 0, 255), 2)\n",
    "\n",
    "    # Draw text\n",
    "    cv2.putText(image, text, (center_x - 40, center_y - 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "\"\"\"## 5. Main Processing Functions\"\"\"\n",
    "\n",
    "def process_image(image):\n",
    "    \"\"\"Process image to detect lane lines, objects, and determine direction.\"\"\"\n",
    "    global CAMERA_MTX, CAMERA_DIST, model\n",
    "\n",
    "    if CAMERA_MTX is None or CAMERA_DIST is None:\n",
    "        print(\"Camera calibration required!\")\n",
    "        return image\n",
    "\n",
    "    if model is None:\n",
    "        print(\"YOLO model not initialized!\")\n",
    "        return image\n",
    "\n",
    "    # Make a copy of the original image\n",
    "    result = image.copy()\n",
    "\n",
    "    try:\n",
    "        # YOLO object detection\n",
    "        results = model(image)\n",
    "\n",
    "        # Draw YOLO detections\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                cls = int(box.cls[0])\n",
    "                conf = float(box.conf[0])\n",
    "                name = model.names[cls]\n",
    "\n",
    "                if conf > 0.5:\n",
    "                    cv2.rectangle(result, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.putText(result, f'{name} {conf:.2f}', (x1, y1 - 10),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in YOLO detection: {str(e)}\")\n",
    "\n",
    "    # Lane detection steps\n",
    "    warped, M_inv = warp(result, CAMERA_MTX, CAMERA_DIST)\n",
    "    binary = binary_thresholded(warped)\n",
    "\n",
    "    # Get line pixels visualization\n",
    "    out_img, leftx, lefty, rightx, righty = find_lane_pixels(binary)\n",
    "\n",
    "    # Fit polynomials\n",
    "    left_fit, right_fit = fit_polynomial(binary)\n",
    "\n",
    "    if left_fit is None or right_fit is None:\n",
    "        return result\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics = calculate_metrics(left_fit, right_fit, binary, leftx, lefty, rightx, righty)\n",
    "\n",
    "    # Calculate tilt\n",
    "    tilt_value, tilt_direction = calculate_tilt(left_fit, right_fit, image.shape)\n",
    "\n",
    "    # Generate points for plotting\n",
    "    ploty = np.linspace(0, image.shape[0]-1, image.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Create lane overlay\n",
    "    warp_zero = np.zeros_like(binary).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
    "    newwarp = cv2.warpPerspective(color_warp, M_inv, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Combine lane detection with result image\n",
    "    result = cv2.addWeighted(result, 1, newwarp, 0.3, 0)\n",
    "\n",
    "    # Draw metrics\n",
    "    result = draw_metrics(result, metrics)\n",
    "\n",
    "    # Draw tilt indicator\n",
    "    result = draw_tilt_indicator(result, tilt_value, tilt_direction)\n",
    "\n",
    "    # Create visualization of binary and warped images\n",
    "    binary_colored = cv2.cvtColor(binary * 255, cv2.COLOR_GRAY2BGR)\n",
    "    warped_viz = warped.copy()\n",
    "\n",
    "    # Draw detected lane lines on warped image\n",
    "    for fitx, color in [(left_fitx, (255, 0, 0)), (right_fitx, (0, 0, 255))]:\n",
    "        pts = np.array([np.transpose(np.vstack([fitx, ploty]))]).astype(np.int32)\n",
    "        cv2.polylines(warped_viz, pts, False, color, thickness=2)\n",
    "\n",
    "    # Create line pixels visualization\n",
    "    line_pixels_viz = np.dstack((binary, binary, binary)) * 255\n",
    "    # Plot line pixels\n",
    "    line_pixels_viz[lefty, leftx] = [255, 0, 0]  # Red for left line\n",
    "    line_pixels_viz[righty, rightx] = [0, 0, 255]  # Blue for right line\n",
    "    # Draw search windows if available from find_lane_pixels\n",
    "    if hasattr(out_img, 'shape'):\n",
    "        window_img = cv2.addWeighted(line_pixels_viz, 1, out_img, 0.3, 0)\n",
    "        line_pixels_viz = window_img\n",
    "\n",
    "    # Combine all visualizations\n",
    "    process_images = [binary_colored, warped_viz, color_warp, line_pixels_viz]\n",
    "    labels = ['Binary Threshold', 'Warped Perspective', 'Lane Detection', 'Line Pixels']\n",
    "    combined_result = combine_images(result, process_images, labels)\n",
    "\n",
    "    return combined_result\n",
    "\n",
    "def process_video(input_path, output_path):\n",
    "    \"\"\"Process video file for lane detection.\"\"\"\n",
    "    clip = VideoFileClip(input_path)\n",
    "\n",
    "    def resize_frame(frame):\n",
    "        # 화면비를 유지하면서 1280x768으로 리사이즈\n",
    "        return cv2.resize(frame, (1280, 720), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "    def process_frame(frame):\n",
    "        # 프레임 리사이즈 후 처리\n",
    "        resized_frame = resize_frame(frame)\n",
    "        return process_image(resized_frame)\n",
    "\n",
    "    processed_clip = clip.fl_image(process_frame)\n",
    "    processed_clip.write_videofile(output_path, audio=False)\n",
    "    clip.close()\n",
    "\n",
    "\"\"\"## 6. Main Execution\"\"\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the lane detection pipeline.\"\"\"\n",
    "    # Initialize system\n",
    "    base_dir, calibration_dir = initialize_system()\n",
    "\n",
    "    print(\"Starting camera calibration...\")\n",
    "    if not initialize_calibration(calibration_dir):\n",
    "        print(\"Camera calibration failed!\")\n",
    "        return\n",
    "\n",
    "    # Input/Output paths\n",
    "    input_dir = os.path.join(base_dir, 'input')\n",
    "    output_dir = os.path.join(base_dir, 'output')\n",
    "\n",
    "    print(\"\\nChecking for video files in the input directory...\")\n",
    "    print(f\"Input directory: {input_dir}\")\n",
    "\n",
    "    # Process all video files in the input directory\n",
    "    while True:\n",
    "        video_files = [f for f in os.listdir(input_dir) if f.endswith(('.mp4', '.avi'))]\n",
    "        if video_files:\n",
    "            break\n",
    "        print(\"Waiting for video files... Please upload to input directory.\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    total_videos = len(video_files)\n",
    "    print(f\"\\nFound {total_videos} video file(s) to process.\")\n",
    "\n",
    "    for idx, video_file in enumerate(video_files, 1):\n",
    "        print(f\"\\nProcessing video {idx}/{total_videos}: {video_file}\")\n",
    "        input_video = os.path.join(input_dir, video_file)\n",
    "        output_video = os.path.join(output_dir, f\"output_{video_file}\")\n",
    "\n",
    "        try:\n",
    "            process_video(input_video, output_video)\n",
    "            print(f\"Successfully processed: {video_file}\")\n",
    "            print(f\"Output saved to: {output_video}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_file}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    print(\"\\nAll video processing complete!\")\n",
    "    print(\"You can find the processed videos in the output directory.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
