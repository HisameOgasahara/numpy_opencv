{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3차. 합본판. 실제로 원하는 건 이걸로 봄."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "calibration_data = pickle.load(open('calibration_data.p','rb'))\n",
    "\n",
    "matrix = calibration_data['camera_matrix']\n",
    "dist_coef = calibration_data['distortion_coefficient']\n",
    "\n",
    "source_points = [(580, 460), (205, 720), (1110, 720), (703, 460)]\n",
    "dest_points = [(320, 0), (320, 720), (960, 720), (960, 0)]\n",
    "\n",
    "warp_matrix = cv2.getPerspectiveTransform(np.float32(source_points), np.float32(dest_points))\n",
    "inv_warp_matrix = cv2.getPerspectiveTransform(np.float32(dest_points), np.float32(source_points))\n",
    "\n",
    "p = { 'sat_thresh': 120, 'light_thresh': 40, 'light_thresh_agr': 205,\n",
    "      'grad_thresh': (0.7, 1.4), 'mag_thresh': 40, 'x_thresh': 20 }\n",
    "\n",
    "sat_thresh = 120\n",
    "light_thresh = 40\n",
    "light_thresh_agr = 205\n",
    "grad_min = 0.7; grad_max = 1.4\n",
    "mag_thresh = 40\n",
    "x_thresh = 20\n",
    "\n",
    "def birdeye_sky_view(ground_image):\n",
    "    temp_image = cv2.undistort(ground_image, matrix, dist_coef, None, matrix)\n",
    "    shape = (temp_image.shape[1] ,temp_image.shape[0]) # (width,height)\n",
    "    # 위쪽에 이미 구해놓았음\n",
    "    # warp_matrix = cv2.getPerspectiveTransform(np.float32(source_points), np.float32(dest_points))\n",
    "    warp_image = cv2.warpPerspective(temp_image, warp_matrix, shape, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warp_image\n",
    "\n",
    "def apply_color_mask(img_hls):   \n",
    "    img_l = img_hls[:, :, 1]\n",
    "    img_s = img_hls[:, :, 2]\n",
    "    color_cond1 = (img_s > sat_thresh) & (img_l > light_thresh)\n",
    "    color_cond2 = img_l > light_thresh_agr\n",
    "    b = np.zeros_like(img_s)\n",
    "    b[(color_cond1 | color_cond2)] = 1\n",
    "    return b\n",
    "\n",
    "def scale_abs(x, m=255):\n",
    "    x = np.absolute(x)\n",
    "    x = np.uint8(m * x / np.max(x))\n",
    "    return x\n",
    "\n",
    "def roi(gray, mn = 125, mx = 1200):\n",
    "  m = np.copy(gray) + 1\n",
    "  m[:, :mn] = 0 \n",
    "  m[:, mx:] = 0 \n",
    "  return m \n",
    "\n",
    "# def show_images(imgs, per_row = 3, per_col = 2, W = 10, H = 5, tdpi = 80):\n",
    "      \n",
    "#   fig, ax = plt.subplots(per_col, per_row, figsize = (W, H), dpi = tdpi)\n",
    "#   ax = ax.ravel()\n",
    "  \n",
    "#   for i in range(len(imgs)):\n",
    "#     img = imgs[i]\n",
    "#     ax[i].imshow(img)\n",
    "  \n",
    "#   for i in range(per_row * per_col):\n",
    "#     ax[i].axis('off')\n",
    "\n",
    "def apply_sobel_mask(img_hls):\n",
    "    img_l = img_hls[:, :, 1]\n",
    "    img_s = img_hls[:, :, 2]  \n",
    "    img_z = np.zeros_like(img_s)     \n",
    "    lx = cv2.Sobel(img_l, cv2.CV_64F, 1, 0, ksize = 5)\n",
    "    ly = cv2.Sobel(img_l, cv2.CV_64F, 0, 1, ksize = 5)\n",
    "    gradl = np.arctan2(np.absolute(ly), np.absolute(lx))\n",
    "    l_mag = np.sqrt(lx**2 + ly**2)\n",
    "    slm, slx, sly = scale_abs(l_mag), scale_abs(lx), scale_abs(ly)\n",
    "    b = np.zeros_like(img_s)\n",
    "    sobel_cond1 = slm > mag_thresh\n",
    "    sobel_cond2 = slx > x_thresh\n",
    "    sobel_cond3 = (gradl > grad_min) & (gradl < grad_max)\n",
    "    b[(sobel_cond1 & sobel_cond2 & sobel_cond3)] = 1  \n",
    "    return b \n",
    "\n",
    "def sobel_breakdown(img): #RGB\n",
    "    img_hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    img_l = img_hls[:, :, 1]\n",
    "    img_s = img_hls[:, :, 2]  \n",
    "    img_z = np.zeros_like(img_s)     \n",
    "    lx = cv2.Sobel(img_l, cv2.CV_64F, 1, 0, ksize = 5)\n",
    "    ly = cv2.Sobel(img_l, cv2.CV_64F, 0, 1, ksize = 5)\n",
    "    gradl = np.arctan2(np.absolute(ly), np.absolute(lx))\n",
    "    l_mag = np.sqrt(lx**2 + ly**2)\n",
    "    slm, slx, sly = scale_abs(l_mag), scale_abs(lx), scale_abs(ly)\n",
    "    sobel_cond1 = slm > mag_thresh\n",
    "    sobel_cond2 = slx > x_thresh\n",
    "    sobel_cond3 = (gradl > grad_min) & (gradl < grad_max)\n",
    "    b1, b2, b3 = img_z.copy(), img_z.copy(), img_z.copy()\n",
    "    b1[(sobel_cond1)] = 255\n",
    "    b2[(sobel_cond2)] = 255\n",
    "    b3[(sobel_cond3)] = 255\n",
    "    return np.dstack((b1, b2,b3))\n",
    "\n",
    "def color_breakdown(rgb_image):\n",
    "    img_hls = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HLS)\n",
    "    img_l = img_hls[:, :, 1]\n",
    "    img_s = img_hls[:, :, 2]\n",
    "    img_z = np.zeros_like(img_s)\n",
    "    color_cond1 = (img_s > sat_thresh) & (img_l > light_thresh)\n",
    "    color_cond2 = img_l > light_thresh_agr\n",
    "    b1, b2 = img_z.copy(), img_z.copy()\n",
    "    b1[(color_cond1)] = 255\n",
    "    b2[(color_cond2)] = 255\n",
    "    return np.dstack((b1, b2, img_z))\n",
    "\n",
    "def lane_filter_apply(rgb_image):\n",
    "    img_hls = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2HLS)   \n",
    "    color_img = apply_color_mask(img_hls)\n",
    "    sobel_img = apply_sobel_mask(img_hls)\n",
    "    filtered_img = cv2.bitwise_or(sobel_img, color_img)\n",
    "    return filtered_img\n",
    "  \n",
    "#여기부터는 curve fit 용\n",
    "\t\n",
    "def next_y(w, h=720, window_height=80):\n",
    "  y_lo = h - (w + 1) * window_height\n",
    "  y_hi = h - w * window_height \n",
    "  return y_lo, y_hi\n",
    "\n",
    "def next_x(current ,margin=100):\n",
    "  x_left = current - margin\n",
    "  x_right = current + margin\n",
    "  return x_left, x_right\n",
    "\n",
    "def next_midx(current, all_pixels_x, pixel_indices, min_pix=50):\n",
    "    if len(pixel_indices) > min_pix:\n",
    "      current = int(np.mean(all_pixels_x[pixel_indices]))\n",
    "    return current\n",
    "\n",
    "def indices_within_boundary(all_pixels_x, all_pixels_y, y_lo, y_hi, x_left, x_right):\n",
    "  cond1 = all_pixels_y >= y_lo\n",
    "  cond2 = all_pixels_y < y_hi\n",
    "  cond3 = all_pixels_x >= x_left\n",
    "  cond4 = all_pixels_x < x_right\n",
    "  return (cond1 & cond2 & cond3 & cond4 ).nonzero()[0]\n",
    "\n",
    "def get_real_curvature(xs, ys, xm_per_pix=(3.7/700), ym_per_pix=(30/720)):\n",
    "    return np.polyfit(ys * ym_per_pix, xs * xm_per_pix, 2)\n",
    "\n",
    "def radius_of_curvature(y, f):\n",
    "    return ((1 + (2 * f[0] * y + f[1])**2)**(1.5)) / np.absolute(2 * f[0])\n",
    "\n",
    "def pixel_locations(all_pixels_x, all_pixels_y, indices):\n",
    "    return all_pixels_x[indices], all_pixels_y[indices]\n",
    "\n",
    "def curves_fit(binary):  \n",
    "  number_of_windows = 9\n",
    "  margin = 100\n",
    "  minimum_pixels = 50\n",
    "  ym_per_pix = 30 / 720\n",
    "  xm_per_pix = 3.7 / 700\n",
    "  glo_left_pixels_indices, glo_right_pixels_indices = [], []\n",
    "  left_pixels_x, left_pixels_y = None, None\n",
    "  right_pixels_x, right_pixels_y = None, None\n",
    "  left_fit_curve_pix, right_fit_curve_pix = None, None\n",
    "  left_fit_curve_f, right_fit_curve_f = None, None\n",
    "  left_radius, right_radius = None, None\n",
    "  vehicle_position, vehicle_position_words = None, None\n",
    "  result = {}\n",
    "\n",
    "  # store details\n",
    "  out_img = np.dstack((binary, binary, binary)) * 255\n",
    "  h, w = binary.shape[0], binary.shape[1]\n",
    "  mid = h/2\n",
    "  window_height = int(h / number_of_windows)  \n",
    "  all_pixels_x = np.array(binary.nonzero()[1])\n",
    "  all_pixels_y = np.array(binary.nonzero()[0]) \n",
    "\n",
    "  # start : w 각 세로라인별 합을 구해서 그값이 가장 큰 세로줄을 시작으로 (좌/우 구분해서)\n",
    "  hist = np.sum(binary[int(h / 2):, :], axis = 0)\n",
    "  mid = int(hist.shape[0] / 2)\n",
    "  mid_leftx = np.argmax(hist[:mid])\n",
    "  mid_rightx = np.argmax(hist[mid:]) + mid\n",
    "  \n",
    "  left_pixels_indices, right_pixels_indices = [], []\n",
    "  x, y = [None, None, None, None], [None, None]\n",
    "  \n",
    "  for w in range(number_of_windows):\n",
    "    y[0], y[1] = next_y(w)\n",
    "    x[0], x[1] = next_x(mid_leftx) \n",
    "    x[2], x[3] = next_x(mid_rightx)\n",
    "\n",
    "    cv2.rectangle(out_img, (x[0], y[0]), (x[1], y[1]), (255, 0, 0), thickness=4)  \n",
    "    cv2.rectangle(out_img, (x[2], y[0]), (x[3], y[1]), (0, 255, 0), thickness=4)\n",
    "    \n",
    "    curr_left_pixels_indices = indices_within_boundary(all_pixels_x, all_pixels_y, y[0], y[1], x[0], x[1])\n",
    "    curr_right_pixels_indices = indices_within_boundary(all_pixels_x, all_pixels_y,y[0], y[1], x[2], x[3])\n",
    "        \n",
    "    left_pixels_indices.append(curr_left_pixels_indices)\n",
    "    right_pixels_indices.append(curr_right_pixels_indices)\n",
    "    \n",
    "    mid_leftx = next_midx(mid_leftx, all_pixels_x, curr_left_pixels_indices)\n",
    "    mid_rightx = next_midx(mid_rightx, all_pixels_x, curr_right_pixels_indices)\n",
    "    \n",
    "  glo_left_pixels_indices = np.concatenate(left_pixels_indices)\n",
    "  glo_right_pixels_indices = np.concatenate(right_pixels_indices)\n",
    "  \n",
    "  left_pixels_x, left_pixels_y = pixel_locations(all_pixels_x, all_pixels_y, glo_left_pixels_indices)\n",
    "  right_pixels_x, right_pixels_y = pixel_locations(all_pixels_x, all_pixels_y, glo_right_pixels_indices)\n",
    "\n",
    "  left_fit_curve_f = get_real_curvature(left_pixels_x, left_pixels_y)\n",
    "  right_fit_curve_f = get_real_curvature(right_pixels_x, right_pixels_y)\n",
    "  \n",
    "  left_radius = radius_of_curvature(h * ym_per_pix, left_fit_curve_f)\n",
    "  right_radius = radius_of_curvature(h *  ym_per_pix, right_fit_curve_f)\n",
    "\n",
    "  #plot\n",
    "  out_img[left_pixels_y, left_pixels_x] = [255, 0, 255]\n",
    "  out_img[right_pixels_y, right_pixels_x] = [0, 255, 255]\n",
    "\n",
    "  left_fit_curve_pix = np.polyfit(left_pixels_y, left_pixels_x, 2)\n",
    "  right_fit_curve_pix = np.polyfit(right_pixels_y, right_pixels_x, 2)\n",
    "\n",
    "  kl, kr = left_fit_curve_pix, right_fit_curve_pix\n",
    "  ys = np.linspace(0, h - 1, h)\n",
    "  \n",
    "  left_xs = kl[0] * (ys**2) + kl[1] * ys + kl[2]\n",
    "  right_xs = kr[0] * (ys**2) + kr[1] * ys + kr[2]\n",
    "  \n",
    "  xls, xrs, ys = left_xs.astype(np.uint32), right_xs.astype(np.uint32), ys.astype(np.uint32)\n",
    "  \n",
    "  t=4\n",
    "  for xl, xr, y in zip(xls, xrs, ys):\n",
    "      cv2.line(out_img, (xl - t, y), (xl + t, y), (255, 255, 0), int(t / 2))\n",
    "      cv2.line(out_img, (xr - t, y), (xr + t, y), (0, 0, 255), int(t / 2))\n",
    "\n",
    "  #update_vehicle_position\n",
    "  y = h\n",
    "  mid = w / 2\n",
    "  kl, kr = left_fit_curve_pix, right_fit_curve_pix\n",
    "  xl = kl[0] * (y**2) + kl[1]* y + kl[2]\n",
    "  xr = kr[0] * (y**2) + kr[1]* y + kr[2]\n",
    "  pix_pos = xl + (xr - xl) / 2\n",
    "  vehicle_position = (pix_pos - mid) * xm_per_pix \n",
    "\n",
    "  if vehicle_position < 0:\n",
    "    vehicle_position_words = str(np.absolute(np.round(vehicle_position, 2))) + \" m left of center\"\n",
    "  elif vehicle_position > 0:\n",
    "    vehicle_position_words = str(np.absolute(np.round(vehicle_position, 2))) + \" m right of center\"\n",
    "  else:\n",
    "    vehicle_position_words = \"at the center\"\n",
    "\n",
    "\n",
    "  result = {\n",
    "    'image': out_img,\n",
    "    'left_radius': left_radius,\n",
    "    'right_radius': right_radius,\n",
    "    'real_left_best_fit_curve': left_fit_curve_f,\n",
    "    'real_right_best_fit_curve': right_fit_curve_f, \n",
    "    'pixel_left_best_fit_curve': left_fit_curve_pix,\n",
    "    'pixel_right_best_fit_curve': right_fit_curve_pix, \n",
    "    'vehicle_position': vehicle_position, \n",
    "    'vehicle_position_words': vehicle_position_words\n",
    "  }\n",
    "  return result\n",
    "  \n",
    "def project_image(ground_image, sky_lane, left_fit, right_fit, color = (0, 255, 0)):\n",
    "    z = np.zeros_like(sky_lane)\n",
    "    sky_lane = np.dstack((z, z, z))\n",
    "\n",
    "    kl, kr = left_fit, right_fit\n",
    "    h = sky_lane.shape[0]\n",
    "    ys = np.linspace(0, h - 1, h)\n",
    "    lxs = kl[0] * (ys**2) + kl[1]* ys +  kl[2]\n",
    "    rxs = kr[0] * (ys**2) + kr[1]* ys +  kr[2]\n",
    "    \n",
    "    pts_left = np.array([np.transpose(np.vstack([lxs, ys]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([rxs, ys])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    cv2.fillPoly(sky_lane, np.int_(pts), color)\n",
    "    \n",
    "    shape = (sky_lane.shape[1], sky_lane.shape[0])\n",
    "    ground_lane = cv2.warpPerspective(sky_lane, inv_warp_matrix, shape)\n",
    "\n",
    "    result = cv2.addWeighted(ground_image, 1, ground_lane, 0.3, 0)\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_video(input_video_path):\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        print('동영상을 열 수 없습니다.')\n",
    "        exit(1)\n",
    "\n",
    "    frame_num = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        try:\n",
    "            img_binary = lane_filter_apply(frame)\n",
    "            birdview_image = birdeye_sky_view(img_binary)\n",
    "            roi_image = roi(birdview_image, mn=125, mx=1200) \n",
    "\n",
    "            birdeye_color = birdeye_sky_view(frame)\n",
    "            sobel_breakdown_img = sobel_breakdown(birdeye_color)\n",
    "            sobel_breakdown_img = cv2.cvtColor(sobel_breakdown_img, cv2.COLOR_RGB2BGR)\n",
    "            color_breakdown_img = color_breakdown(birdeye_color)\n",
    "            color_breakdown_img = cv2.cvtColor(color_breakdown_img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            result = curves_fit(birdview_image)\n",
    "            processed_frame = project_image(frame, birdview_image, result['pixel_left_best_fit_curve'], result['pixel_right_best_fit_curve'])\n",
    "            processed_frame = cv2.cvtColor(processed_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # 최종 영상의 크기 가져오기\n",
    "            final_height, final_width = processed_frame.shape[:2]\n",
    "\n",
    "            # 상단 영상 크기 조정 (최종 영상의 1/4 크기)\n",
    "            resized_height = final_height // 4\n",
    "            resized_width = final_width // 4\n",
    "\n",
    "            birdview_image2 = cv2.resize(birdeye_color, (resized_width, resized_height), interpolation=cv2.INTER_AREA)\n",
    "            sobel_breakdown_img = cv2.resize(sobel_breakdown_img, (resized_width, resized_height), interpolation=cv2.INTER_AREA)\n",
    "            color_breakdown_img = cv2.resize(color_breakdown_img, (resized_width, resized_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            # 수정된 부분: 마지막 이미지를 curves_fit 결과로 변경\n",
    "            curves_fit_image = cv2.resize(result['image'], (resized_width, resized_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "            # 상단 이미지들을 hconcat으로 합침\n",
    "            top_row = np.concatenate((birdview_image2, sobel_breakdown_img, color_breakdown_img, curves_fit_image), axis=1)\n",
    "\n",
    "            # 프레임 번호 추가\n",
    "            frame_now = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "            processed_frame = cv2.putText(processed_frame, f'{int(frame_now):04d} / {int(frame_num):04d}', (10, 30),\n",
    "                                        cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)\n",
    "\n",
    "            # 상단 이미지와 하단 이미지를 vconcat으로 합침\n",
    "            final_result = np.concatenate((top_row, processed_frame), axis=0)\n",
    "\n",
    "            cv2.imshow('Final Result', final_result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing frame {cap.get(cv2.CAP_PROP_POS_FRAMES)}: {e}\")\n",
    "\n",
    "        if cv2.waitKey(33) == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video = 'videos/project_video.mp4'  # 입력 비디오 파일 경로\n",
    "process_video(input_video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
